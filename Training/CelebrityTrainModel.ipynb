{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCvuq2-cixRP",
        "colab_type": "code",
        "outputId": "f956f450-5544-4b7a-8951-0d082892b4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2                \n",
        "import matplotlib.pyplot as plt      \n",
        "from keras.preprocessing.image import ImageDataGenerator,image\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.optimizers import RMSprop, SGD\n",
        " \n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "%matplotlib inline         \n",
        "random.seed(8675309)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRaYcYT15ac0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyzN5Xw5lSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Colab Notebooks/5-celebrity-faces-dataset/data'\n",
        "resnet50weight = '/content/drive/My Drive/Colab Notebooks/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8dZGdNCBjtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozkLLUV17C5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width, img_height = 192, 192\n",
        "\n",
        "train_data_dir = os.path.join(data_dir, 'train')\n",
        "validation_data_dir = os.path.join(data_dir, 'val')\n",
        "nb_train_samples = 93\n",
        "nb_validation_samples = 25\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "numclasses = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHSahQu7Ihe",
        "colab_type": "code",
        "outputId": "b59a8ef4-21aa-4cb9-d0fa-3a9eed44362e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        " # this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    zoom_range = 0.1, # Randomly zoom image \n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    #shear_range=0.2,\n",
        "    vertical_flip=False,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 93 images belonging to 5 classes.\n",
            "Found 25 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvg1iBC47Mjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65nu7pJv7ZHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet50tl(input_shape, outclass, sigma='sigmoid'):\n",
        "    \n",
        "    base_model = None\n",
        "    base_model = keras.applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
        "    base_model.load_weights(resnet50weight)\n",
        "    \n",
        "    top_model = Sequential()\n",
        "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    for i in range(2):\n",
        "        top_model.add(Dense(4096, activation='relu'))\n",
        "        top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(outclass, activation=sigma))\n",
        "\n",
        "    model = None\n",
        "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC5e-pZM7cNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = mobile_net(input_shape, numclasses, 'softmax')\n",
        "lr = 1e-5\n",
        "decay = 1e-7 #0.0\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J2t3eal7_RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/model_weights.h5\", monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min') \n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size,\n",
        "    callbacks = [checkpoint],\n",
        "verbose =1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpe-xhc4W2mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrHuhEwHTd2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator,image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "labels = ['ben_afflek',  'elton_john',  'jerry_seinfeld',  'madonna',  'mindy_kaling']\n",
        "#test_imgs = ['ben_afflek/httpabsolumentgratuitfreefrimagesbenaffleckjpg.jpg']\n",
        "# test_img = os.path.join(validation_data_dir, \"madonna/httpassetsrollingstonecomassetsimagesalbumreviewaffaceabdcccaeedjpg.jpg\")\n",
        "\n",
        "test_img = \"/content/drive/My Drive/Colab Notebooks/elton-john.jpg\"\n",
        "\n",
        "img = image.load_img(test_img, target_size=(img_width, img_height))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x /= 255.\n",
        "classes = model.predict(x)\n",
        "result = np.squeeze(classes)\n",
        "result_indices = np.argmax(result)\n",
        "\n",
        "img = cv2.imread(test_img, cv2.IMREAD_COLOR)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.axis('off')\n",
        "plt.title(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}